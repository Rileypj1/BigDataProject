{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_2016 = sc.textFile(\"s3://gdelt-open-data/events/2016*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = sample_2016.map(lambda l: l.split('\\t'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"practice\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "html = urlopen(\"http://gdeltproject.org/data/lookups/CSV.header.dailyupdates.txt\").read().rstrip().decode('utf-8')\n",
    "columns = html.split('\\t')\n",
    "df = spark.createDataFrame(parts, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"gdelt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "CollectLimit 5\n",
      "+- *(1) Project [Actor1Code#645, Actor1Name#646, Actor1CountryCode#647, Actor1Religion1Code#650]\n",
      "   +- Scan ExistingRDD[GLOBALEVENTID#640,SQLDATE#641,MonthYear#642,Year#643,FractionDate#644,Actor1Code#645,Actor1Name#646,Actor1CountryCode#647,Actor1KnownGroupCode#648,Actor1EthnicCode#649,Actor1Religion1Code#650,Actor1Religion2Code#651,Actor1Type1Code#652,Actor1Type2Code#653,Actor1Type3Code#654,Actor2Code#655,Actor2Name#656,Actor2CountryCode#657,Actor2KnownGroupCode#658,Actor2EthnicCode#659,Actor2Religion1Code#660,Actor2Religion2Code#661,Actor2Type1Code#662,Actor2Type2Code#663,... 34 more fields]\n"
     ]
    }
   ],
   "source": [
    "sqlWay = spark.sql(\"\"\"\n",
    "SELECT Actor1Code, Actor1Name, Actor1CountryCode, Actor1Religion1Code\n",
    "FROM gdelt\n",
    "LIMIT 5\n",
    "\"\"\")\n",
    "sqlWay.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|Actor1Name|count|\n",
      "+----------+-----+\n",
      "|    SOMALI|32047|\n",
      "|   ARMENIA|80388|\n",
      "|      A US|28942|\n",
      "|     OSAGE| 1632|\n",
      "|    HUNTER|32782|\n",
      "+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#output here looks nice, but not sure if table set up correctly (i.e. Actor1Name being a column and the rows\n",
    "#seem like other column records)\n",
    "from pyspark.sql.functions import window, column, desc, col\n",
    "\n",
    "df\\\n",
    ".selectExpr(\"Actor1Code\", \n",
    "              \"Actor1Name\", \n",
    "              \"Actor1CountryCode\", \n",
    "              \"Actor1Religion1Code\",\n",
    "           \"NumMentions\")\\\n",
    ".groupBy(col(\"Actor1Name\"))\\\n",
    ".count()\\\n",
    ".show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-------------+-------------+-----------+----------+-----------+\n",
      "|GLOBALEVENTID|EventCode|EventBaseCode|EventRootCode|NumMentions|NumSources|NumArticles|\n",
      "+-------------+---------+-------------+-------------+-----------+----------+-----------+\n",
      "|    498554164|      051|          051|           05|          6|         2|          6|\n",
      "|    498554165|      051|          051|           05|          6|         2|          6|\n",
      "|    498554166|      070|          070|           07|         12|         2|         12|\n",
      "|    498554167|      051|          051|           05|          6|         2|          6|\n",
      "|    498554168|      051|          051|           05|          2|         2|          2|\n",
      "+-------------+---------+-------------+-------------+-----------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df\\\n",
    ".selectExpr(\"GLOBALEVENTID\",\n",
    "            \"EventCode\",\n",
    "            \"EventBaseCode\",\n",
    "            \"EventRootCode\",\n",
    "            \"NumMentions\", \n",
    "            \"NumSources\",\n",
    "            \"NumArticles\")\\\n",
    ".show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
