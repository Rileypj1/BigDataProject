{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "     .appName(\"Test\") \\\n",
    "     .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_rows=250\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.ticker import FormatStrFormatter, FuncFormatter\n",
    "\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.sql.functions import expr, regexp_replace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319104809\n",
      "root\n",
      " |-- EventDate: string (nullable = true)\n",
      " |-- MentionSource: string (nullable = true)\n",
      " |-- MentionIdentifier: string (nullable = true)\n",
      " |-- MentionDocTone: float (nullable = true)\n",
      " |-- Month: string (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      "\n",
      "None\n",
      "0:03:31.615381\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "df_mentions = spark.read.parquet(\"s3://labadie-gdelt-tradewar/mentions.parquet\")\n",
    "df_mentions = df_mentions.withColumn(\"MentionDocTone\",func.col(\"MentionDocTone\").cast(\"float\"))\n",
    "df_mentions.cache()\n",
    "\n",
    "print(df_mentions.count())\n",
    "\n",
    "print(df_mentions.printSchema())\n",
    "\n",
    "print(datetime.now()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+--------------+------+----+\n",
      "|EventDate|       MentionSource|   MentionIdentifier|MentionDocTone| Month|Year|\n",
      "+---------+--------------------+--------------------+--------------+------+----+\n",
      "| 20150306|          hitfix.com|/motion-captured/...|     -2.728513|201503|2015|\n",
      "| 20150306|          fijione.tv|/isis-claims-amer...|    -14.444445|201503|2015|\n",
      "| 20150306| billingsgazette.com|/news/state-and-r...|     -10.36036|201503|2015|\n",
      "| 20150306|          news24.com|/SouthAfrica/News...|     -6.553398|201503|2015|\n",
      "| 20150306|         cnsnews.com|/news/article/col...|     -2.857143|201503|2015|\n",
      "| 20150306|         recorder.ca|/2015/03/06/boy-1...|     -9.756098|201503|2015|\n",
      "| 20150306|   yorknewstimes.com|/news/authorities...|      6.451613|201503|2015|\n",
      "| 20150306|            kmbc.com|/news/ferguson-le...|    -1.8181819|201503|2015|\n",
      "| 20150306|          kagstv.com|/News/KAGSNews/ID...|     0.4796163|201503|2015|\n",
      "| 20150306|          mondaq.com|/unitedstates/x/3...|   -0.54711246|201503|2015|\n",
      "| 20150306|lajuntatribunedem...|/article/ZZ/20150...|     1.3513514|201503|2015|\n",
      "| 20150306|             play.tm|/news/827489003/s...|     1.6949153|201503|2015|\n",
      "| 20150306|         nytimes.com|/2015/03/07/upsho...|    -2.0134227|201503|2015|\n",
      "| 20150306|       inquisitr.com|/1901801/roy-moor...|     2.7027028|201503|2015|\n",
      "| 20150306|        usatoday.com|/story/travel/fli...|    -2.4173028|201503|2015|\n",
      "| 20150306|     wickedlocal.com|dedham./article/Z...|     1.3793104|201503|2015|\n",
      "| 20190205|            kark.com|/news/local-news/...|     -8.661417|201902|2019|\n",
      "| 20190205|            oann.com|/u-s-envoy-to-hol...|    -1.4056225|201902|2019|\n",
      "| 20190205|            kscj.com|/2019/02/04/local...|     0.5494506|201902|2019|\n",
      "| 20190205|chestertontribune...|/PoliceFireEmerge...|    -1.5789474|201902|2019|\n",
      "+---------+--------------------+--------------------+--------------+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_mentions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Across Fields\n",
    "We could show how many countries are represented by the dataset.  Might just be interesting to show the breadth of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Sources Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Unique Publishers 108411\n"
     ]
    }
   ],
   "source": [
    "print(\"Num Unique Publishers\",df_mentions.select([\"MentionSource\"]).distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Publishers That Published at Least Once a Month and Mentioned Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[EventDate: string, MentionSource: string, MentionIdentifier: string, MentionDocTone: float, Month: string, Year: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find sources that published at least once a month\n",
    "mentions_by_month=df_mentions.groupby([\"MentionSource\",\"Month\"]).count()\n",
    "max_months = mentions_by_month.groupby(\"MentionSource\").count().agg(func.max(\"count\").alias(\"max_count\")).take(1)[0].max_count\n",
    "sources_all_months=mentions_by_month.groupby(\"MentionSource\").count().where(func.col(\"count\")==max_months). \\\n",
    "    selectExpr(\"MentionSource as x\")\n",
    "sources_all_months.cache()\n",
    "\n",
    "# find sources who had a URL that included trump at least once\n",
    "also_mentioned_trump=df_mentions.join(sources_all_months, df_mentions.MentionSource==sources_all_months.x).drop(\"x\")\n",
    "also_mentioned_trump=also_mentioned_trump.where(df_mentions.MentionIdentifier.rlike('trump')). \\\n",
    "    selectExpr(\"MentionSource as y\").distinct()\n",
    "also_mentioned_trump.cache()\n",
    "\n",
    "# build a filtered dataset\n",
    "filtered_mentions=df_mentions.join(also_mentioned_trump,df_mentions.MentionSource==also_mentioned_trump.y).drop(\"y\")\n",
    "filtered_mentions.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Publishers At Least Once a Month 6883\n",
      "Num Publishers At Least Once a Month and Mentioned Trump 5726\n",
      "    Num Articles 226989999\n"
     ]
    }
   ],
   "source": [
    "print(\"Num Publishers At Least Once a Month\", sources_all_months.count())\n",
    "print(\"Num Publishers At Least Once a Month and Mentioned Trump\", also_mentioned_trump.count())\n",
    "print(\"    Num Articles\",filtered_mentions.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Articles with Zero Tone: 5172066\n"
     ]
    }
   ],
   "source": [
    "print(\"Num Articles with Zero Tone:\",filtered_mentions.where(filtered_mentions.MentionDocTone==0).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publishers: 5726\n",
      "Articles: 221817927\n"
     ]
    }
   ],
   "source": [
    "print(\"Publishers:\",\n",
    "      filtered_mentions.where(filtered_mentions.MentionDocTone!=0).select(\"MentionSource\").distinct().count())\n",
    "print(\"Articles:\",filtered_mentions.where(filtered_mentions.MentionDocTone!=0).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store Filtered Dataset in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_mentions=filtered_mentions.where(filtered_mentions.MentionDocTone!=0)\n",
    "filtered_mentions.write.parquet(\"s3://labadie-gdelt-tradewar/filtered_mentions.parquet\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stats on That Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(EventDate='20170221', MentionSource='iheart.com', MentionIdentifier='kmag991./onair/maverick-48550/the-new-people-of-walmart-pics-15581180/', MentionDocTone=58.16023635864258, Month='201702', Year='2017'),\n",
       " Row(EventDate='20181114', MentionSource='dailystar.co.uk', MentionIdentifier='/news/latest-news/742410/Prince-Charles-birthday-Prince-of-Wales-70th-birthday-party-who-will-attend', MentionDocTone=36.3636360168457, Month='201811', Year='2018'),\n",
       " Row(EventDate='20180820', MentionSource='fltimes.com', MentionIdentifier='/briefs/midlakes-middle-school-hosts-awards-ceremony/article_9625d27a-3b7b-5a7a-a5b5-195d2fc959d2.html', MentionDocTone=33.50983428955078, Month='201808', Year='2018'),\n",
       " Row(EventDate='20180820', MentionSource='fltimes.com', MentionIdentifier='/briefs/midlakes-middle-school-hosts-awards-ceremony/article_9625d27a-3b7b-5a7a-a5b5-195d2fc959d2.html', MentionDocTone=33.50983428955078, Month='201808', Year='2018'),\n",
       " Row(EventDate='20170306', MentionSource='ghanaweb.com', MentionIdentifier='/GhanaHomePage/NewsArchive/Highlights-of-2017-Ghana-Music-Honours-516055', MentionDocTone=31.578947067260742, Month='201703', Year='2017'),\n",
       " Row(EventDate='20160405', MentionSource='leaderherald.com', MentionIdentifier='/page/polls.detail/id/758/John-Kerry-will-be-the-first-U-S--secretary-of-state-to-visit-Hiroshima-s-Peace-Memorial-Park-this-month--Washington-has-never-apologized-for-the-attack--Will-Kerry-.html', MentionDocTone=31.578947067260742, Month='201604', Year='2016'),\n",
       " Row(EventDate='20160405', MentionSource='leaderherald.com', MentionIdentifier='/page/polls.detail/id/758/John-Kerry-will-be-the-first-U-S---.html', MentionDocTone=31.578947067260742, Month='201604', Year='2016'),\n",
       " Row(EventDate='20180817', MentionSource='pghcitypaper.com', MentionIdentifier='/Blogh/archives/2018/08/17/best-of-pgh-2018-party-photo-slideshow', MentionDocTone=31.578947067260742, Month='201808', Year='2018'),\n",
       " Row(EventDate='20160405', MentionSource='leaderherald.com', MentionIdentifier='/page/polls.detail/id/758/John-Kerry-will-be-the-first-U-S---.html', MentionDocTone=31.578947067260742, Month='201604', Year='2016'),\n",
       " Row(EventDate='20160405', MentionSource='leaderherald.com', MentionIdentifier='/page/polls.detail/id/758/John-Kerry-will-be-the-first-U-S--secretary-of-state-to-visit-Hiroshima-s-Peace-Memorial-Park-this-month--Washington-has-never-apologized-for-the-attack--Will-Kerry-.html', MentionDocTone=31.578947067260742, Month='201604', Year='2016')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_mentions.orderBy(\"MentionDocTone\",ascending=False).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|avg(MentionDocTone)|\n",
      "+-------------------+\n",
      "|-3.4193885499365715|\n",
      "+-------------------+\n",
      "\n",
      "Avg Tone None\n",
      "+-------------------+\n",
      "|min(MentionDocTone)|\n",
      "+-------------------+\n",
      "|          -77.89855|\n",
      "+-------------------+\n",
      "\n",
      "Min Tone None\n",
      "+-------------------+\n",
      "|max(MentionDocTone)|\n",
      "+-------------------+\n",
      "|          58.160236|\n",
      "+-------------------+\n",
      "\n",
      "Max Tone None\n"
     ]
    }
   ],
   "source": [
    "print(\"Avg Tone\",filtered_mentions.where(filtered_mentions.MentionDocTone!=0). \\\n",
    "      select(filtered_mentions.MentionDocTone.cast('float')).agg(func.mean(\"MentionDocTone\")).show())\n",
    "print(\"Min Tone\",filtered_mentions.where(filtered_mentions.MentionDocTone!=0). \\\n",
    "      select(filtered_mentions.MentionDocTone.cast('float')).agg(func.min(\"MentionDocTone\")).show())\n",
    "print(\"Max Tone\",filtered_mentions.where(filtered_mentions.MentionDocTone!=0). \\\n",
    "      select(filtered_mentions.MentionDocTone.cast('float')).agg(func.max(\"MentionDocTone\")).show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line_over_time(x,y_dict,y_axis_label,filename):\n",
    "    fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "    data_to_plot = list(y_dict.items())\n",
    "    \n",
    "    # first set of data\n",
    "    ax.plot(x,data_to_plot[0][1],label=data_to_plot[0][0])\n",
    "    ax.set_xlabel(\"Week of Year\")\n",
    "    ax.tick_params(axis=\"x\", rotation=30)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(4))\n",
    "    ax.set_ylabel(y_axis_label)\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"Plots/\"+filename+\".png\", \n",
    "                facecolor=fig.get_facecolor(), \n",
    "                edgecolor='none')\n",
    "    \n",
    "    \n",
    "def plot_line_over_time_two_y_axis(x,y_dict,filename):\n",
    "    fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "    data_to_plot = list(y_dict.items())\n",
    "    \n",
    "    # first set of data\n",
    "    ax.plot(x,data_to_plot[0][1],label=data_to_plot[0][0])\n",
    "    ax.set_xlabel(\"Week of Year\")\n",
    "    ax.tick_params(axis=\"x\", rotation=30)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(4))\n",
    "    ax.set_ylabel(data_to_plot[0][0])\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "    \n",
    "    if len(data_to_plot) > 1:\n",
    "        for i in range(1,len(data_to_plot)):\n",
    "            ax2 = ax.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "            ax2.xaxis.set_major_locator(ticker.MultipleLocator(4))\n",
    "            ax2.set_ylabel(data_to_plot[i][0])\n",
    "            ax2.plot(x,data_to_plot[i][1],data_to_plot[i][1])      \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"Plots/\"+filename+\".png\", \n",
    "                facecolor=fig.get_facecolor(), \n",
    "                edgecolor='none')\n",
    "    \n",
    "    \n",
    "def counts_by_week_year(relevant_events):\n",
    "    # group by day\n",
    "    all_events_by_day = pd.DataFrame(relevant_events.groupby(\"EventDate\").count().collect())\n",
    "    all_events_by_day.columns = [\"Date\",\"Count\"]\n",
    "    all_events_by_day[\"Date\"] = pd.to_datetime(all_events_by_day[\"Date\"].astype(str), format='%Y%m%d', errors=\"coerce\")\n",
    "    all_events_by_day = all_events_by_day[all_events_by_day[\"Date\"] >= datetime.strptime(\"2015-04-01\",\"%Y-%m-%d\")]\n",
    "    all_events_by_day = all_events_by_day.sort_values(by=\"Date\")\n",
    "\n",
    "    # get week number of year\n",
    "    all_events_by_day[\"Week\"] = ((all_events_by_day[\"Date\"].dt.dayofyear-1)//7+1).apply(lambda x: '{0:0>2}'.format(min(x,52)))\n",
    "    all_events_by_day[\"Year\"] = all_events_by_day[\"Date\"].dt.year.astype(str)\n",
    "    all_events_by_day[\"YearWeek\"] = all_events_by_day[\"Year\"] + \"-\" + all_events_by_day[\"Week\"]\n",
    "    all_events_by_day = all_events_by_day.groupby(by=\"YearWeek\")[\"Count\"].sum().reset_index()\n",
    "\n",
    "    return all_events_by_day\n",
    "\n",
    "\n",
    "def avg_tone_by_week_year(relevant_events):\n",
    "    all_events_by_day = pd.DataFrame(relevant_events.groupby(\"EventDate\").agg(func.mean(\"MentionDocTone\").alias(\"MentionDocTone\")).collect())\n",
    "    all_events_by_day.columns = [\"Date\",\"MentionDocTone\"]\n",
    "    all_events_by_day[\"Date\"] = pd.to_datetime(all_events_by_day[\"Date\"].astype(str), format='%Y%m%d', errors=\"coerce\")\n",
    "    all_events_by_day = all_events_by_day[all_events_by_day[\"Date\"] >= datetime.strptime(\"2015-04-01\",\"%Y-%m-%d\")]\n",
    "    all_events_by_day = all_events_by_day.sort_values(by=\"Date\")\n",
    "\n",
    "    # get week number of year\n",
    "    all_events_by_day[\"Week\"] = ((all_events_by_day[\"Date\"].dt.dayofyear-1)//7+1).apply(lambda x: '{0:0>2}'.format(min(x,52)))\n",
    "    all_events_by_day[\"Year\"] = all_events_by_day[\"Date\"].dt.year.astype(str)\n",
    "    all_events_by_day[\"YearWeek\"] = all_events_by_day[\"Year\"] + \"-\" + all_events_by_day[\"Week\"]\n",
    "    all_events_by_day = all_events_by_day.groupby(by=\"YearWeek\")[\"MentionDocTone\"].mean().reset_index()\n",
    "\n",
    "    return all_events_by_day\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Count of All Events by Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-eba25dab40fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# group by week_year\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts_by_week_year\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_mentions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# group by week and plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-eb08f4407b2f>\u001b[0m in \u001b[0;36mcounts_by_week_year\u001b[0;34m(relevant_events)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcounts_by_week_year\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant_events\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# group by day\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mall_events_by_day\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"EventDate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mall_events_by_day\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Date\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Count\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mall_events_by_day\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Date\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_events_by_day\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%Y%m%d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"coerce\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \"\"\"\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "# group by week_year\n",
    "data = counts_by_week_year(df_mentions)\n",
    "\n",
    "# group by week and plot\n",
    "x=data[\"YearWeek\"]\n",
    "y_dict = {}\n",
    "y_dict[\"All Event Count\"] = data[\"Count\"]\n",
    "plot_line_over_time(x,y_dict,\"Count\",\"All_Events_Counts\")\n",
    "\n",
    "print(datetime.now()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot trump mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get relevant events\n",
    "relevant_events = df_mentions.where(df_mentions.MentionIdentifier.rlike('trump'))\n",
    "\n",
    "# group by week_year\n",
    "counts = counts_by_week_year(relevant_events)\n",
    "tone = avg_tone_by_week_year(relevant_events)\n",
    "\n",
    "# plot\n",
    "x=counts[\"YearWeek\"]\n",
    "y_dict = {}\n",
    "y_dict[\"Count\"] = counts[\"Count\"]\n",
    "y_dict[\"Tone\"]=tone[\"MentionDocTone\"]\n",
    "\n",
    "plot_line_over_time_two_y_axis(x,y_dict,\"Trump_Events_Counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot tariff mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get relevant events\n",
    "relevant_events = df_mentions.where(df_mentions.MentionIdentifier.rlike('tariff')\n",
    "                                  | df_mentions.MentionIdentifier.rlike('trade*war'))\n",
    "\n",
    "# group by week_year\n",
    "data = counts_by_week_year(relevant_events)\n",
    "\n",
    "# group by week and plot\n",
    "x=data[\"YearWeek\"]\n",
    "y_dict = {}\n",
    "y_dict[\"Count\"] = data[\"Count\"]\n",
    "plot_line_over_time(x,y_dict,\"Count\",\"Tariff_Events_Counts\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
